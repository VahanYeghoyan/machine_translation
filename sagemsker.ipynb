{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:26:57.076594Z",
     "start_time": "2024-08-02T12:26:47.081077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "# Enable memory growth for GPUs if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = 'armenian_tokenizer'\n",
    "tokenizer = tf.saved_model.load(model_name).am\n",
    "save_path = \"/home/vahan/Documents/machine_translation/latest_correction_model\"\n",
    "loaded_model = tf.saved_model.load(save_path)\n",
    "print(\"Model and tokenizer loaded successfully\")\n",
    "\n",
    "class Corrector(tf.Module):\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, sentence, max_length=65):\n",
    "        assert isinstance(sentence, tf.Tensor)\n",
    "        if len(sentence.shape) == 0:\n",
    "            sentence = sentence[tf.newaxis]\n",
    "\n",
    "        sentence = self.tokenizer.tokenize(sentence).to_tensor()\n",
    "        encoder_input = sentence\n",
    "\n",
    "        start, end = self.tokenizer.tokenize([''])[0]\n",
    "        start, end = start[tf.newaxis], end[tf.newaxis]\n",
    "\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        output_array = output_array.write(0, start)\n",
    "\n",
    "        for i in tf.range(max_length):\n",
    "            output = tf.transpose(output_array.stack())\n",
    "            predictions = self.model.generate(\n",
    "                tf.cast(encoder_input, tf.int32),\n",
    "                tf.cast(output, tf.int32)\n",
    "            )\n",
    "            predictions = predictions[:, -1:, :]\n",
    "            predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "            output_array = output_array.write(i + 1, predicted_id[0])\n",
    "\n",
    "            if predicted_id == end:\n",
    "                break\n",
    "\n",
    "        output = tf.transpose(output_array.stack())\n",
    "        text = self.tokenizer.detokenize(output)[0]\n",
    "        tokens = self.tokenizer.lookup(output)[0]\n",
    "\n",
    "        return text, tokens\n",
    "\n",
    "corrector = Corrector(tokenizer, loaded_model)\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, normalized_transcription):\n",
    "        self.normalized_transcription = normalized_transcription\n",
    "        self.new_sentences = []\n",
    "\n",
    "    def perform_preprocessing(self):\n",
    "        pattern = r'.*\\d.*'\n",
    "        filtered_data = [sentence.lower() for sentence in self.normalized_transcription if not re.match(pattern, sentence)]\n",
    "        for sent in filtered_data:\n",
    "            new_sent = \"\".join(\n",
    "                [ch for ch in sent if ord(\"ա\") <= ord(ch) <= ord(\"և\") or ch in {\",\", \"։\", \" \", \":\"}]\n",
    "            ).strip()\n",
    "            new_sent = new_sent.replace(\":\", \"։\").replace(\"եւ\", \"և\")\n",
    "            new_sent = re.sub(r\"\\s+\", \" \", new_sent)\n",
    "\n",
    "            if new_sent:\n",
    "                self.new_sentences.append(new_sent)\n",
    "        return self.new_sentences\n",
    "\n",
    "# Example usage\n",
    "sentence = \"բարև,վսկու առհեքս ինցքան է\"\n",
    "prp = Preprocessing([sentence])\n",
    "filtered_sentence = prp.perform_preprocessing()\n",
    "\n",
    "translated_text, translated_tokens = corrector(tf.constant(filtered_sentence))\n",
    "translated_text = translated_text.numpy().decode(\"utf-8\")\n",
    "translated_text"
   ],
   "id": "ef171af9e3323fc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'բարեւ , ոսկու արտահոսք ինչքան է'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:27:08.635547Z",
     "start_time": "2024-08-02T12:27:08.629181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "updated_sentence = translated_text.replace('եւ', 'և')\n",
    "print(updated_sentence)\n"
   ],
   "id": "8a851d8ea8c41871",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "բարև , ոսկու արտահոսք ինչքան է\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:03:53.652419Z",
     "start_time": "2024-08-05T11:03:53.560042Z"
    }
   },
   "cell_type": "code",
   "source": "'բարեւ , ոսկու առեք ինչքան է'",
   "id": "e1b4303147f847fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'բարեւ , ոսկու առեք ինչքան է'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:04:13.478374Z",
     "start_time": "2024-08-05T11:04:13.475981Z"
    }
   },
   "cell_type": "code",
   "source": "print(55)",
   "id": "9b0ebcf7fa5d268f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d40d8d932f38ce87"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
